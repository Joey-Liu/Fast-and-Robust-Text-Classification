{
    "dataset_reader": {
        "type": "universal_text_reader",
        "use_subtrees": true,
        "granularity": "2-class"
    },
    "validation_dataset_reader": {
        "type": "universal_text_reader",
        "use_subtrees": false,
        "granularity": "2-class"
    },
    "train_data_path": "../bcn_output/yelp_L1/train_c_500.0-l1.txt",
    "validation_data_path": "../bcn_output/agnews_L1/dev_c_500.0-l1.txt",
    "selector": {
        "type": "selector",
        "text_field_embedder": {
            "tokens": {
                "type": "embedding",
                "embedding_dim": 50,
                "trainable": false
            }
        },
        "embedding_dropout": 0.25
    },
    "model": {
        "type": "skim_lstm",
        "text_field_embedder": {
            "tokens": {
                "pretrained_file": "../.allennlp/datasets/glove_300",
                "type": "embedding",
                "embedding_dim": 300,
                "trainable": false
            }
        },
        "embedding_dropout": 0.25,
        "pre_encode_feedforward": {
            "input_dim": 300,
            "num_layers": 1,
            "hidden_dims": [
                300
            ],
            "activations": [
                "relu"
            ],
            "dropout": [
                0.25
            ]
        },
        "big_dim": 300,
        "small_dim": 300,
        "gamma": 1,
        "integrator": {
            "type": "lstm",
            "input_size": 300,
            "hidden_size": 300,
            "num_layers": 1,
            "bidirectional": true
        },
        "integrator_dropout": 0.1,
        "output_layer": {
            "input_dim": 1800,
            "num_layers": 3,
            "output_dims": [
                1200,
                100,
                5
            ],
            "pool_sizes": 4,
            "dropout": [
                0.2,
                0.3,
                0.0
            ]
        }
    },
    "iterator": {
        "type": "bucket",
        "sorting_keys": [
            [
                "tokens",
                "num_tokens"
            ]
        ],
        "batch_size": 32
    },
    "trainer": {
        "num_epochs": 40,
        "patience": 1,
        "grad_norm": 5.0,
        "validation_metric": "+accuracy",
        "cuda_device": 0,
        "optimizer": {
            "type": "adam",
            "lr": 0.001
        },
        "optimizer_selector": {
            "type": "adam",
            "lr": 0.001
        }
    }
}